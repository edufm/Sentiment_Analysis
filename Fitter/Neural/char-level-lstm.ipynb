{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifica√ß√£o de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cartacapital', 'conexaopolitica', 'EstadaoEconomia', 'EstadaoPolitica', 'folha', 'folha_mercado', 'folha_poder', 'g1', 'g1economia', 'g1politica', 'GloboNews', 'hbredda', 'jairbolsonaro', 'OGloboPolitica', 'OGlobo_Economia', 'pedrocerize', 'RevistaEpoca', 'RevistaISTOE', 'UOL', 'UOLEconomia', 'valoreconomico', 'VEJA']\n"
     ]
    }
   ],
   "source": [
    "#Verifica os dados no diretorio\n",
    "\n",
    "Data = os.listdir(\"../../Filter/Tweets_Filtered/\")\n",
    "for i in range(len(Data)):\n",
    "    Data[i] = Data[i].split(\".\")[0]\n",
    "    \n",
    "print(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pessoas = [\"realDonaldTrump\", \"jairbolsonaro\", \"hbredda\", \"gui_benchimol\", \"pedrocerize\"]\n",
    "\n",
    "NoticiasPolitica = [\"OGloboPolitica\", \"folha_poder\", \"GloboNews\", \"EstadaoPolitica\", \n",
    "                    \"RevistaEpoca\", \"valoreconomico\", \"g1politica\", \"conexaopolitica\", \"EstadaoEconomia\", \n",
    "                    \"UOLEconomia\", \"folha_mercado\", \"g1economia\", \"OGlobo_Economia\", \"valoreconomico\"]\n",
    "\n",
    "Noticias = [\"UOL\", \"folha\", \"g1\", \"VEJA\", \"cartacapital\", \"RevistaISTOE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monta um dicionario com todos datasets de twites de todas as pessoas\n",
    "Alvo = NoticiasPolitica\n",
    "\n",
    "\n",
    "AllData = {}\n",
    "\n",
    "for i in Alvo:\n",
    "    if i in Data:\n",
    "        AllData[i] = pd.read_csv(\"../../Filter/Tweets_Filtered/{0}\".format(i+\".csv\"), sep=\";\", decimal=\",\", encoding='utf-16')\n",
    "    else:\n",
    "        print(\"{0} n√£o disponivel\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "carlos ignora ponto final do pai e volta a atacar mour√£o estranh√≠ssimo alinhamento com pol√≠ticos que detestam o‚Ä¶ \n",
      "----------\n",
      "pol√≠cia civil deflagra opera√ß√£o em todo o pa√≠s contra foragidos da justi√ßa \n",
      "----------\n",
      "an√°lise decis√£o do stj sobre lula n√£o muda situa√ß√£o do pt \n",
      "----------\n",
      "bom dia leitor siga aqui as principais not√≠cias da pol√≠tica nacional e os acontecimentos mais importantes pelo pa‚Ä¶ \n",
      "----------\n",
      "lula pode ser solto ap√≥s decis√£o do stj entenda \n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "printrange = range(0, 5)\n",
    "print(\"-\"*10)\n",
    "for i in printrange:\n",
    "    print(AllData[Alvo[0]][\"Texto\"].iloc[i])\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllX = {}\n",
    "\n",
    "for i in Alvo:\n",
    "    AllX[i] = list(AllData[i][\"Texto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carlos ignora ponto final do pai e volta a atacar mour√£o estranh√≠ssimo alinhamento com pol√≠ticos que detestam o‚Ä¶ ', 'pol√≠cia civil deflagra opera√ß√£o em todo o pa√≠s contra foragidos da justi√ßa ']\n"
     ]
    }
   ],
   "source": [
    "print(AllX[Alvo[0]][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for i in Alvo:\n",
    "    X = X + AllX[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtra os dataframes para agrupar os tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pessoa</th>\n",
       "      <th>Data</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OGloboPolitica</td>\n",
       "      <td>2019-04-24 12:56:33</td>\n",
       "      <td>carlos ignora ponto final do pai e volta a ata...</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OGloboPolitica</td>\n",
       "      <td>2019-04-24 10:58:35</td>\n",
       "      <td>pol√≠cia civil deflagra opera√ß√£o em todo o pa√≠s...</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OGloboPolitica</td>\n",
       "      <td>2019-04-24 10:35:24</td>\n",
       "      <td>an√°lise decis√£o do stj sobre lula n√£o muda sit...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OGloboPolitica</td>\n",
       "      <td>2019-04-24 10:21:14</td>\n",
       "      <td>bom dia leitor siga aqui as principais not√≠cia...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OGloboPolitica</td>\n",
       "      <td>2019-04-24 00:04:58</td>\n",
       "      <td>lula pode ser solto ap√≥s decis√£o do stj entenda</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OGloboPolitica</td>\n",
       "      <td>2019-04-23 22:59:07</td>\n",
       "      <td>advogado de lula promete apresentar todos os r...</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OGloboPolitica</td>\n",
       "      <td>2019-04-23 22:49:05</td>\n",
       "      <td>funcion√°rio da vale diz que diretores sabiam d...</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OGloboPolitica</td>\n",
       "      <td>2019-04-23 22:40:49</td>\n",
       "      <td>bolsonaro quer ponto final em briga entre carl...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OGloboPolitica</td>\n",
       "      <td>2019-04-23 22:22:42</td>\n",
       "      <td>‚Äún√£o esperava nada positivo sobre o julgamento...</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OGloboPolitica</td>\n",
       "      <td>2019-04-23 22:04:21</td>\n",
       "      <td>quando um n√£o quer dois n√£o brigam diz mour√£o...</td>\n",
       "      <td>35</td>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pessoa                 Data  \\\n",
       "0  OGloboPolitica  2019-04-24 12:56:33   \n",
       "1  OGloboPolitica  2019-04-24 10:58:35   \n",
       "2  OGloboPolitica  2019-04-24 10:35:24   \n",
       "3  OGloboPolitica  2019-04-24 10:21:14   \n",
       "4  OGloboPolitica  2019-04-24 00:04:58   \n",
       "5  OGloboPolitica  2019-04-23 22:59:07   \n",
       "6  OGloboPolitica  2019-04-23 22:49:05   \n",
       "7  OGloboPolitica  2019-04-23 22:40:49   \n",
       "8  OGloboPolitica  2019-04-23 22:22:42   \n",
       "9  OGloboPolitica  2019-04-23 22:04:21   \n",
       "\n",
       "                                               Texto  Retweets  Likes  URL  \n",
       "0  carlos ignora ponto final do pai e volta a ata...         8     30    1  \n",
       "1  pol√≠cia civil deflagra opera√ß√£o em todo o pa√≠s...         2     13    1  \n",
       "2  an√°lise decis√£o do stj sobre lula n√£o muda sit...         1      6    1  \n",
       "3  bom dia leitor siga aqui as principais not√≠cia...         0      1    1  \n",
       "4   lula pode ser solto ap√≥s decis√£o do stj entenda          0     13    1  \n",
       "5  advogado de lula promete apresentar todos os r...         2     22    1  \n",
       "6  funcion√°rio da vale diz que diretores sabiam d...         5     17    1  \n",
       "7  bolsonaro quer ponto final em briga entre carl...         3     12    1  \n",
       "8  ‚Äún√£o esperava nada positivo sobre o julgamento...        12     46    1  \n",
       "9   quando um n√£o quer dois n√£o brigam diz mour√£o...        35    181    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test = AllData[Alvo[0]].head(10)\n",
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-25 ['rt expressoepoca desist√™ncia de m√°rcio lacerda agita elei√ß√µes em minas gerais ex prefeito de belo horizonte abriu m√£o da candidatura nest‚Ä¶', 'rt expressoepoca stj solta executivo de multinacional da √°rea da sa√∫de preso na lava jato trata se de antonio georgete ']\n",
      "2019-04-24 ['lula pode ser solto ap√≥s decis√£o do stj entenda ', 'advogado de lula promete apresentar todos os recursos que lei permite para absolv√™ lo ']\n",
      "2019-04-23 ['dono oficial do s√≠tio de atibaia pede autoriza√ß√£o judicial para vend√™ lo ', 'defesa de lula diz que n√£o foi intimada sobre julgamento no stj pautado para ter√ßa ']\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "DateInterval = [datetime.datetime.strptime(\"17:00:00\", \"%H:%M:%S\").time(), \n",
    "                datetime.datetime.strptime(\"9:00:00\", \"%H:%M:%S\").time()]\n",
    "\n",
    "oneday = datetime.timedelta(days=1)\n",
    "daytweets = []\n",
    "tweets_data = {}\n",
    "\n",
    "for i in Alvo:\n",
    "    datas = AllData[i]['Data']\n",
    "    tweets = AllData[i]['Texto']\n",
    "    likes = AllData[i]['Likes']\n",
    "    retweets = AllData[i]['Retweets']\n",
    "    Started = True\n",
    "    lastday = datetime.datetime.strptime(datas[0], '%Y-%m-%d %H:%M:%S').date()\n",
    "    \n",
    "    for j in range (0, len(datas)):\n",
    "        \n",
    "        data = datetime.datetime.strptime(datas[j], '%Y-%m-%d %H:%M:%S').date()\n",
    "        time = datetime.datetime.strptime(datas[j], '%Y-%m-%d %H:%M:%S').time()\n",
    "        \n",
    "        if data != lastday:\n",
    "            delta = abs(int(str(data - lastday).split(\" \")[0]))\n",
    "            if int(delta) >= 2:\n",
    "                #Acaba o periodo por for√ßa bruta\n",
    "                Started = False\n",
    "                if(str(data) not in tweets_data):\n",
    "                    tweets_data[str(data)] = daytweets\n",
    "                else:\n",
    "                    for k in daytweets:\n",
    "                        tweets_data[str(data+oneday)].append(k)\n",
    "                daytweets = []\n",
    "        \n",
    "        #Test to 00:00\n",
    "        First = (DateInterval[0] < time) and (time < datetime.datetime.strptime(\"23:59:59\", \"%H:%M:%S\").time())\n",
    "        #Test from 00:00\n",
    "        Second = (datetime.datetime.strptime(\"00:00:01\", \"%H:%M:%S\").time() < time) and (time < DateInterval[1])\n",
    "\n",
    "        if First or Second:\n",
    "            Started = True\n",
    "            #Esta dentro do periodo\n",
    "            daytweets.append(tweets[j])\n",
    "\n",
    "        elif Started:\n",
    "            #Acaba o periodo\n",
    "            Started = False\n",
    "            if(str(data+oneday) not in tweets_data):\n",
    "                tweets_data[str(data+oneday)] = daytweets\n",
    "            else:\n",
    "                for k in daytweets:\n",
    "                    tweets_data[str(data+oneday)].append(k)\n",
    "            daytweets = []\n",
    "                \n",
    "        lastday = data\n",
    "\n",
    "Dates = list(tweets_data.keys())\n",
    "\n",
    "for i in range(3):\n",
    "    print(Dates[i], tweets_data[Dates[i]][0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtra as a√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolsa = pd.read_excel('../../Dados_Bolsa/Twt.xlsx', sheet_name=\"1h\", usecols=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ibov</th>\n",
       "      <th>Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-08 10:00:00</td>\n",
       "      <td>86283.67</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-08 11:00:00</td>\n",
       "      <td>85686.68</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-08 12:00:00</td>\n",
       "      <td>85408.61</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-08 13:00:00</td>\n",
       "      <td>85267.66</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-08 14:00:00</td>\n",
       "      <td>85686.73</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ibov     Price  Volume   Ticks\n",
       "0 2018-10-08 10:00:00  86283.67        0    119\n",
       "1 2018-10-08 11:00:00  85686.68        0    120\n",
       "2 2018-10-08 12:00:00  85408.61        0    120\n",
       "3 2018-10-08 13:00:00  85267.66        0    120\n",
       "4 2018-10-08 14:00:00  85686.73        0    120"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bolsa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1110"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibov_len  = len(bolsa['ibov'])\n",
    "ibov_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa os resultados da IBov em classes (zonas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x[0]), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numero de 0s:\", y.count(0))\n",
    "print(\"Numero de 1s:\", y.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Propor√ß√£o de 0s:\", y.count(0)/len(y))\n",
    "print(\"Propor√ß√£o de 1s:\", y.count(1)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-08 {'abertura': 86283.67, 'fechamento': 86083.91, 'variacao': 0}\n",
      "2018-10-09 {'abertura': 85864.42, 'fechamento': 86087.55, 'variacao': 0}\n",
      "2018-10-10 {'abertura': 84590.04, 'fechamento': 83679.11, 'variacao': 0}\n",
      "2018-10-11 {'abertura': 84492.8, 'fechamento': 82921.08, 'variacao': 2}\n"
     ]
    }
   ],
   "source": [
    "ibov_data_precos_v2 = {}\n",
    "# c√©lula para identificar os pre√ßos de abertura e fechamento de cada dia\n",
    "for i in range(0, ibov_len):\n",
    "    data_completa = datetime.datetime.strptime(str(bolsa['ibov'][i]), '%Y-%m-%d %H:%M:%S')\n",
    "    preco = bolsa['Price'][i]\n",
    "    data = data_completa.strftime(\"%Y-%m-%d\")\n",
    "    if data not in ibov_data_precos_v2:\n",
    "        ibov_data_precos_v2[data] = {}\n",
    "        ibov_data_precos_v2[data]['abertura'] = preco\n",
    "        ibov_data_precos_v2[data]['fechamento'] = preco #caso s√≥ tenhamos informa√ß√£o de uma hora dentro de um dia, assumimos esse preco como o de fechamento tbm\n",
    "        dia_anterior_completo =  data_completa - datetime.timedelta(days=1)\n",
    "        dia_anterior_data = dia_anterior_completo.strftime(\"%Y-%m-%d\")\n",
    "        if(dia_anterior_data in ibov_data_precos_v2):\n",
    "            dia_anterior_fechamento = ibov_data_precos_v2[dia_anterior_data]['fechamento']\n",
    "            delta_fechamento=preco/dia_anterior_fechamento-1\n",
    "            if(delta_fechamento>(0.2*10**-2)):\n",
    "                ibov_data_precos_v2[data]['variacao'] = 2\n",
    "            elif(delta_fechamento<(-0.2*10**-2)):\n",
    "                ibov_data_precos_v2[data]['variacao'] = 0\n",
    "            else:\n",
    "                ibov_data_precos_v2[data]['variacao'] = 1\n",
    "        else:\n",
    "            ibov_data_precos_v2[data]['variacao'] = 0 #se n√£o tivermos informa√ß√µes sobre o dia anterior, assumimos que a variacao caiu\n",
    "    else:\n",
    "        if i < (ibov_len - 1):\n",
    "            data_seguinte = datetime.datetime.strptime(str(bolsa['ibov'][i+1]), '%Y-%m-%d %H:%M:%S')\n",
    "            if data_seguinte.date() > data_completa.date():\n",
    "                ibov_data_precos_v2[data]['fechamento'] = preco\n",
    "                \n",
    "Datesibov = list(ibov_data_precos_v2.keys())\n",
    "                \n",
    "for i in range(4):\n",
    "    print(Datesibov[i], ibov_data_precos_v2[Datesibov[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44665"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2018-10-29'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-a3094f673968>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mibov_data_precos_v2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mXBits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mYBits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mibov_data_precos_v2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'variacao'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '2018-10-29'"
     ]
    }
   ],
   "source": [
    "YBits = []\n",
    "XBits = []\n",
    "\n",
    "for data in ibov_data_precos_v2:\n",
    "    if(data in tweets_data):\n",
    "        for j in tweets_data[data]:\n",
    "            XBits.append(j)\n",
    "            YBits.append(ibov_data_precos_v2[data]['variacao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "0.442419623059867\n",
      "0.17281042128603105\n",
      "0.384769955654102\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "classes=to_categorical(class_list)\n",
    "print(classes)\n",
    "\n",
    "classest = np.transpose(classes)\n",
    "\n",
    "for i in range(len(classest)):\n",
    "    print(list(classest[i]).count(1)/len(classest[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A separa√ß√£o por zonas, criou uma classe com 44% de predomin√¢ncia, ou seja, temos uma baseline para um modelom classificador de 44%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gera√ß√£o de sequ√™ncia a partir dos textos em n√≠veis de car√°cteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
    "tk.fit_on_texts(XBits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando o Tokenizer √© inicializado apenas dois par√¢metros s√£o importantes.\n",
    "char_level=True: isso torna a a√ß√£o texts_to_sequences() pronta para processar o texto em n√≠vel de car√°cter\n",
    "oov_token='UNK': isso adicionar um car√°cter desconhecido do vacubul√°rio, o que permite que mesmo se novos caracteres aparecerem o c√≥digo ser√° capaz de rodar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNK': 1,\n",
       " ' ': 2,\n",
       " 'a': 3,\n",
       " 'e': 4,\n",
       " 'o': 5,\n",
       " 'r': 6,\n",
       " 'i': 7,\n",
       " 's': 8,\n",
       " 'd': 9,\n",
       " 'n': 10,\n",
       " 't': 11,\n",
       " 'm': 12,\n",
       " 'c': 13,\n",
       " 'l': 14,\n",
       " 'p': 15,\n",
       " 'u': 16,\n",
       " 'v': 17,\n",
       " 'b': 18,\n",
       " 'g': 19,\n",
       " 'f': 20,\n",
       " '√£': 21,\n",
       " 'h': 22,\n",
       " 'q': 23,\n",
       " '√ß': 24,\n",
       " 'z': 25,\n",
       " 'j': 26,\n",
       " '√°': 27,\n",
       " '√©': 28,\n",
       " 'x': 29,\n",
       " '√≠': 30,\n",
       " '‚Ä¶': 31,\n",
       " '√™': 32,\n",
       " '1': 33,\n",
       " '√≥': 34,\n",
       " '0': 35,\n",
       " '2': 36,\n",
       " '√µ': 37,\n",
       " '√∫': 38,\n",
       " '3': 39,\n",
       " 'w': 40,\n",
       " '√†': 41,\n",
       " '√¢': 42,\n",
       " '8': 43,\n",
       " 'y': 44,\n",
       " '5': 45,\n",
       " '9': 46,\n",
       " '4': 47,\n",
       " 'k': 48,\n",
       " '7': 49,\n",
       " '6': 50,\n",
       " '√¥': 51,\n",
       " '‚Äò': 52,\n",
       " '‚Äô': 53,\n",
       " '‚Äú': 54,\n",
       " '¬∫': 55,\n",
       " '‚Äù': 56,\n",
       " '¬™': 57,\n",
       " '‚Äî': 58,\n",
       " 'üëá': 59,\n",
       " '\\u2066': 60,\n",
       " '‚Äì': 61,\n",
       " '√º': 62,\n",
       " '\\u2069': 63,\n",
       " 'Ô∏è': 64,\n",
       " 'üòç': 65,\n",
       " '\\xa0': 66,\n",
       " '¬∞': 67,\n",
       " 'üëÄ': 68,\n",
       " '‚ù§': 69,\n",
       " 'üéâ': 70,\n",
       " 'üòâ': 71,\n",
       " 'ü§î': 72,\n",
       " '¬¥': 73,\n",
       " 'üò±': 74,\n",
       " 'üèª': 75,\n",
       " 'ü§©': 76,\n",
       " 'üëè': 77,\n",
       " 'üé∂': 78,\n",
       " 'üëç': 79,\n",
       " 'üòÇ': 80,\n",
       " '‚úà': 81,\n",
       " 'üá∏': 82,\n",
       " 'üá¶': 83,\n",
       " 'ü§£': 84,\n",
       " '√´': 85,\n",
       " 'üé¨': 86,\n",
       " 'üí™': 87,\n",
       " 'üáß': 88,\n",
       " 'üá∑': 89,\n",
       " 'üåä': 90,\n",
       " 'üëÜ': 91,\n",
       " '‚ö°': 92,\n",
       " '√±': 93,\n",
       " 'üçª': 94,\n",
       " 'ü•ö': 95,\n",
       " 'üç≥': 96,\n",
       " 'üë´': 97,\n",
       " 'üèº': 98,\n",
       " 'üê£': 99,\n",
       " 'üß¨': 100,\n",
       " 'üòä': 101,\n",
       " '√§': 102,\n",
       " 'üê∂': 103,\n",
       " 'üéä': 104,\n",
       " '‚ö†': 105,\n",
       " '‚ò∫': 106,\n",
       " 'üç≤': 107,\n",
       " 'üíÜ': 108,\n",
       " 'üèΩ': 109,\n",
       " '\\u200d': 110,\n",
       " '‚ôÄ': 111,\n",
       " '‚§µ': 112,\n",
       " 'üòé': 113,\n",
       " '¬º': 114,\n",
       " 'üëà': 115,\n",
       " 'üëâ': 116,\n",
       " 'üçø': 117,\n",
       " '‚öΩ': 118,\n",
       " 'üôÄ': 119,\n",
       " 'ü¶à': 120,\n",
       " '‚û°': 121,\n",
       " 'üé®': 122}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tk.texts_to_sequences(XBits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "115\n",
      "117\n",
      "114\n",
      "73\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(sequences):\n",
    "    print(len(s))\n",
    "    if i > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=140\n",
    "\n",
    "pad_X = pad_sequences(sequences, maxlen=input_size, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14432, 140)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_X=np.array(pad_X)\n",
    "pad_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len(tk.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights=[]\n",
    "embedding_weights.append(np.zeros(vocab_size))\n",
    "\n",
    "for char, i in tk.word_index.items():\n",
    "    onehot=np.zeros(vocab_size)\n",
    "    onehot[i-1]=1\n",
    "    embedding_weights.append(onehot)\n",
    "embedding_weights=np.array(embedding_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 122)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding_weights.shape)\n",
    "embedding_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando a rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.layers import LSTM, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "num_of_classes=3\n",
    "input_size=input_size\n",
    "embedding_size=vocab_size\n",
    "dropout_p = 0.5\n",
    "optimizer = 'adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "\n",
    "embedding_layer=Embedding(vocab_size +1, \n",
    "                         embedding_size,\n",
    "                         input_length=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14432, 140)\n",
      "(14432, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pad_X.shape)\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 140)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 140, 122)          15006     \n",
      "_________________________________________________________________\n",
      "unified_lstm (UnifiedLSTM)   (None, 140, 256)          388096    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 35840)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               18350592  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 18,755,233\n",
      "Trainable params: 18,755,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model construction\n",
    "inputs = Input(shape=(input_size,))\n",
    "embedded_sequence = embedding_layer(inputs)\n",
    "x = LSTM(256, return_sequences=True, activation='selu')(embedded_sequence)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='selu')(x)\n",
    "x = Dropout(dropout_p)(x)\n",
    "prediction = Dense(num_of_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=prediction)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED=42\n",
    "x_train, x_test, y_train, y_test = train_test_split(pad_X, classes, test_size=.07, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13421 samples, validate on 1011 samples\n",
      "Epoch 1/5\n",
      "13421/13421 [==============================] - 268s 20ms/sample - loss: 1.0291 - accuracy: 0.4679 - val_loss: 1.0269 - val_accuracy: 0.4599\n",
      "Epoch 2/5\n",
      "13421/13421 [==============================] - 275s 20ms/sample - loss: 0.9953 - accuracy: 0.4968 - val_loss: 1.0353 - val_accuracy: 0.4491\n",
      "Epoch 3/5\n",
      "13421/13421 [==============================] - 263s 20ms/sample - loss: 0.9671 - accuracy: 0.5159 - val_loss: 1.0401 - val_accuracy: 0.4777\n",
      "Epoch 4/5\n",
      "13421/13421 [==============================] - 261s 19ms/sample - loss: 0.9431 - accuracy: 0.5452 - val_loss: 1.0598 - val_accuracy: 0.4441\n",
      "Epoch 5/5\n",
      "13421/13421 [==============================] - 316s 24ms/sample - loss: 0.9218 - accuracy: 0.5608 - val_loss: 1.0611 - val_accuracy: 0.4649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ebd2fb7a58>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=64,\n",
    "          epochs=5,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hope.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# load model from single file\n",
    "model = load_model('hope.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
